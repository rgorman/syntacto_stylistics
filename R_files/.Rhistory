holder.l <- cite.l[[i]][j]
df <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
xyz <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
xyz
df <- matrix(nrow=1, ncol=3)
colnames(df) <- c("First", "Last", "Size")
cite.param.m <-df[-1,]
View(cite.param.m)
authors.v <-  gsub(" ", "_", xyz)
authors.v <- gsub("\\.|:", "", authors.v)
suffix <- ".txt"
i <-1
for (i in 1:length(authors.v)) {
names_for_chunks <- append(names_for_chunks, paste(authors.v[i], suffix, sep=""))
}
names_for_chunks <- NULL
i <-1
for (i in 1:length(authors.v)) {
names_for_chunks <- append(names_for_chunks, paste(authors.v[i], suffix, sep=""))
}
cite.l[[1]]
doc.object[1]
sword.cite[1]
cite.v[1]
ceiling(x/max.length)
ceiling(x/max.length)
split(cite.v, ceiling(x/max.length))
x/max.length
ceiling(x/max.length)
View(df)
chunk.name.l[[1]]
chunk.name.l[[2]]
holder.l[[1]]
chunk.name.l[[6]]
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
xyz
authors.v <-  gsub(" ", "_", xyz) # replace white spance with underscores
authors.v <- gsub("\\.|:", "", authors.v) # eleminate dots and colons
suffix <- ".txt" # create object with suffix for text files
names_for_chunks <- NULL
i <-1
for (i in 1:length(authors.v)) {
names_for_chunks <- append(names_for_chunks, paste(authors.v[i], suffix, sep=""))
}
sWord.l <- list() # create empty list object to contain output
i <- 1 # set incrementizer to 1
for(i in 1:length(files.v)) {
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE) # make R object of xml file
chunk.size <-1000 # set chunk size
sword.content <- getNodeSet(doc.object, "//sWord") # create vector and populate with <sWord> elements
sWord.v <- paste(sapply(sword.content, xmlValue), sep=" ", collapse=NULL) # populate vector with content of sWord elements
sWord.v <- tolower(sWord.v) # change contents of vector to lower case
divisor <- length(sWord.v)/chunk.size
max.length <- length(sWord.v)/divisor
x <- seq_along(sWord.v)
sWord.l[[i]] <- split(sWord.v, ceiling(x/max.length))
}
str(sWord.l[[1]][1])
str(sWord.l[[2]][1])
length(sWord.l)
xyz.l <- list()
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
xyz.l <- list()
j <- 1
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
xyz.l[[i]][j] <- holder.l[[1]][1]
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
holder.l <- cite.l[[i]][j]
xyz.l[[i]][j] <- holder.l[[1]][1]
xyz.l[[1]][j] <- holder.l[[1]][1]
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
xyz.l <- list()
j <- 1
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
xyz.l[[1]][j] <- holder.l[[1]][1]
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
xyz.l[[1]][1] <- poop
xyz.l[[1]][1] <- "poop"
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
xyz.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
xyz.l[[i]] <- holder.l[[1]][1]
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
xyz.l[[1]]
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
xyz.l <- list()
j <- 1
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
xyz.l[[i]] <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
xyz.l[[1]]
test.l <- lapply(xyz.l, gsub(" ", "_"))
test.l <- lapply(xyz.l, gsub(" ", "_", xyz.l))
test.l <- lapply(xyz.l, underscore.f)
underscore.f <- function(x) {
gsub(" ", "_", x)
return(x)
}
test.l <- lapply(xyz.l, underscore.f)
test.l[[1]]
underscore.f <- function(x) {
gsub(" ", "_", x)
}
test.l <- lapply(xyz.l, underscore.f)
test.l[[1]]
dots.f <- function(x) {
gsub("\\.|:", "", x)
}
test.l <- lapply(test.l, dots.f)
test.l[[1]]
suffix <- ".txt" # create object with suffix for text files
suffix.f <- function(x) {
paste(x, suffix, sep="")
}
test.l <- lapply(test.l, suffix.f)
test.l[[1]]
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
metadata.l <- list()
j <- 1
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
}
metadata.l <- lapply(metadata.l, underscore.f)
metadata.l <- lapply(metadata.l, dots.f)
metadata.l <- lapply(metadata.l, suffix.f)
metadata.l[[1]]
metadata.l[[2]]
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
metadata.l <- list()
j <- 1
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
xyz <- NULL
}
metadata.l[[1]]
metadata.l[[2]]
metadata.l[[3]]
metadata.l <- lapply(metadata.l, underscore.f)
metadata.l <- lapply(metadata.l, dots.f)
metadata.l <- lapply(metadata.l, suffix.f)
metadata.l[[2]]
sWord.l[[1]][1]
sapply(sWord.l[[1]][1], paste, sep="", collapse=" ")
i <- 1
j <- 1
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j])
folder <- "../rel_pos_prose/test_reuse/"
folder_file <- paste(folder, metadata.l[[i]][j])
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
i <- 1
j <- 1
i <- 1
for (i in 1:length(sWord.l)) {
for (j in j:lenght(sWord.l[i])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
j <- 1
}
i <- 1
i <- 1
for (i in 1:length(sWord.l)) {
for (j in j:length(sWord.l[i])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
j <- 1
}
length(sWord.l[[1]])
i <- 1
j <- 1
i <- 1
for (i in 1:length(sWord.l)) {
for (j in 1:length(sWord.l[i])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
j <- 1
}
i <- 1
j <- 1
i <- 1
for (i in 1:length(sWord.l)) {
j <- 1
for (j in 1:length(sWord.l[i])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
}
i <- 1
for (j in 1:length(sWord.l[i])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
length(sWord.l[[1]])
j <- 1
for (j in 1:25) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
j <- 1
for (j in 1:25) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
length(sWord.l[[2]])
i <- 2
j <- 1
for (j in 1:32) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
length(sWord.l[[i]])
i <- 3
length(sWord.l[[i]])
j <- 1
for (j in 1:length(sWord.l[[i]])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
i <- 4
j <- 1
for (j in 1:length(sWord.l[[i]])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
i <- 5
j <- 1
for (j in 1:length(sWord.l[[i]])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
j <- 1
for (j in 1:length(sWord.l[[i]])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
i <- 6
j <- 1
for (j in 1:length(sWord.l[[i]])) {
data_results <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(data_results, file=folder_file)
}
i <- 1
for (i in 1:length(sWord.l)) {
poop
}
for (i in 1:length(sWord.l)) {
1+i
}
i <- 1
for (i in 1:length(sWord.l)) {
total <- 1+i
}
i <- 1
for (j in j:length(sWord.l[[i]])) {
total <- 1+j
}
j <- 1
for (j in j:length(sWord.l[[i]])) {
total <- 1+j
}
for (i in 1:length(sWord.l)) {
j <- 1
for (j in j:length(sWord.l[[i]])) {
total <- 1+j
}
}
final_data <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
i <- 1
j <- 1
for (i in 1:length(sWord.l)) {
j <- 1
for (j in j:length(sWord.l[[i]])) {
final_data <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
total <- 1+j
}
}
folder <- "../rel_pos_prose/test/" # folder for file destination
i <- 1
j <- 1
folder_file <- paste(folder, metadata.l[[i]][j])
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
i <- 1
total <- NULL
for (i in 1:length(sWord.l)) {
j <- 1
for (j in j:length(sWord.l[[i]])) {
final_data <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
total <- 1+j
}
}
j <- 1
i <- 1
for (i in 1:length(sWord.l)) {
j <- 1
for (j in j:length(sWord.l[[i]])) {
final_data <- sapply(sWord.l[[i]][j], paste, sep="", collapse=" ")
folder_file <- paste(folder, metadata.l[[i]][j], sep="")
write(final_data, file=folder_file)
}
}
require(textreuse)
require(textreuse)
input.directory <- "../rel_pos_prose/test_reuse"
corpus <- TextReuseCorpus(dir=input.directory,  keep_tokens = TRUE)
results.m <- pairwise_compare(corpus, jaccard_similarity, )
write.csv(results.m, file="../rel_pos_prose/jaccard_1_Dec6.csv")
minhash <- minhash_generator(n=200)
corpus <- TextReuseCorpus(dir=input.directory, minhash_function=minhash,  keep_tokens = TRUE)
head(corpus[[1]])
vignette("textreuse-minhash", package = "textreuse")
corpus <- TextReuseCorpus(dir=input.directory, minhash_func=minhash,  keep_tokens = TRUE)
lsh_threshold(200, 100)
lsh_threshold(200, 50)
lsh_threshold(200, 40)
lsh_threshold(200, 100)
lash.results <- lsh(corpus, 100)
lsh_candidates(lash.results)
results.m <- lsh_compare(lsh_candidates(lash.results), corpus, jaccard_similarity)
write.csv(results.m, file="../rel_pos_prose/jaccard_2_Dec6.csv")
corpus <- TextReuseCorpus(dir=input.directory, keep_tokens = TRUE)
results.m <- pairwise_compare(corpus, jaccard_similarity, directional = TRUE)
write.csv(results.m, file="../rel_pos_prose/jaccard_3_Dec6.csv")
write.csv(results.m, file="../rel_pos_prose/jaccard_3_Dec6.csv")
write.csv(results.m, file="../rel_pos_prose/jaccard_4_Dec6.csv")
library(XML)
source("code/corpusFunctions.R")
input.dir <- "../rel_pos_prose"
files.v <- dir(path=input.dir, pattern=".*xml")
cite.l <- list()
for(i in 1:length(files.v)){
doc.object <- xmlTreeParse(file.path(input.dir, files.v[i]), useInternalNodes=TRUE) # create object containing xml for each file
chunk.size <-1000 # set size of chunks into which to divide file
sword.cite <- getNodeSet(doc.object, "//sWord/@cite") # extract @cite attribues from each sWord element in file
cite.v <- paste(sword.cite, collapse=NULL) # extract content from the @cite attribues
divisor <- length(cite.v)/chunk.size
max.length <- length(cite.v)/divisor
x <- seq_along(cite.v)
cite.l[[i]] <- split(cite.v, ceiling(x/max.length))
}
summary(cite.l)
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
metadata.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
xyz <- NULL
}
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
chunk.name.l[[i]] <- rbind(df, c(holder.l[[1]][1], holder.l[[1]][length(holder.l[[1]])], length(holder.l[[1]])))
}
xyz <- NULL
}
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
metadata.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
}
xyz <- NULL
}
metadata.l[[3]]
j <- 1
i <- 1
holder.l <- list()
chunk.name.l <- list()
xyz <- NULL # this vector hold the chunk names for later use.
metadata.l <- list()
for (i in 1:length(files.v)) {
j <- 1
for (j in j:length(cite.l[[i]])) {
holder.l <- cite.l[[i]][j]
xyz <- append(xyz, holder.l[[1]][1])
metadata.l[[i]] <- append(xyz, holder.l[[1]][1])
}
xyz <- NULL
}
metadata.l[[3]]
metadata.l[[2]]
metadata.l[[1]]
metadata.l[[3]]
metadata.l[[4]]
metadata.l[[5]]
metadata.l[[6]]
head(corpus)
head(corpus[[1]])
unique(corpus[[1$hashes]])
unique(corpus[[1]]$hashes)
count(unique(corpus[[1]]$hashes))
length(unique(corpus[[1]]$hashes))
corpus[[1]]
wordcount(corpus)
corpus <- TextReuseCorpus(dir=input.directory, tokenizer = tokenize_ngrams(n=1) keep_tokens = TRUE, )
corpus <- TextReuseCorpus(dir=input.directory, tokenizer = tokenize_ngrams, n=1 keep_tokens = TRUE, )
corpus <- TextReuseCorpus(dir=input.directory, tokenizer = tokenize_ngrams, n=1, keep_tokens = TRUE, )
corpus[[1]]
head(corpus[[1]])
length(unique(corpus[[1]]$hashes))
results.m <- pairwise_compare(corpus, jaccard_similarity)
write.csv(results.m, file="../rel_pos_prose/jaccard_5_Dec6.csv")
results.m <- pairwise_compare(corpus, jaccard_similarity, directional = TRUE)
write.csv(results.m, file="../rel_pos_prose/jaccard_1_Dec7.csv")
metadata.l[[2]]
metadata.l[[1]]
metadata.l[[3]]
metadata.l[[4]]
metadata.l[[5]]
metadata.l[[6]]
